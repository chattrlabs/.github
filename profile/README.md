# 🧩 Chattr Labs

**Chattr — modular AI pipeline (voice → knowledge → chat).**  
Focused on speed, scale, and clarity.  

---

## 💡 Overview
Chattr Labs builds modular components for turning human language into machine-ready intelligence:  

- **voice/** → speech-to-text with Faster-Whisper  
- **knowledge/** → embeddings, vector indexing, retrieval  
- **chat/** → large language model reasoning (Ollama, etc.)  
- **toolbelt/** → lightweight scripts for orchestration  

The goal is not another chatbot, but a pipeline:  
**voice → knowledge → chat.**

---

## 🔎 Not That Chattr
There’s also a *Chattr* package for **R**, aimed at researchers.  
This project is different: built in **Python, containers, and clusters — where AI scales in practice.**

---

## ⚙️ Principles
- **Efficiency** → pipelines that minimize friction and overhead.  
- **Modularity** → independent parts that connect like LEGO.  
- **Transparency** → fewer black boxes, more clear processes.  

---

## ⚡ Notes
- Designed for containerized environments (Proxmox, Docker, etc.).  
- Optimized for CPU first, GPU optional.  
- Output designed to be integrated with downstream LLMs or custom applications.  
- Occasional system nags may read: *“Too much compute — please upgrade to enterprise.”*  

---

## 📌 Status
Early stage. Modules are being built incrementally.  
Expect active iteration, rapid changes, and modular growth.
